{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ92vVSNdpRcg2T/K6KEU/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhavi0987/Model-Evaluation-and-Hyperparameter-Tuning/blob/main/assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from scipy.stats import randint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Step 1: Load Dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Step 2: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Feature Scaling (Important for Logistic Regression and SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 4: Define Models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC()\n",
        "}\n",
        "\n",
        "# Step 5: Evaluation Function\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Step 6: Train and Evaluate Initial Models\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name in ['Logistic Regression', 'SVM']:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        scores = evaluate_model(model, X_test_scaled, y_test)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        scores = evaluate_model(model, X_test, y_test)\n",
        "    results[name] = scores\n",
        "\n",
        "print(\"\\nInitial Model Evaluation Results:\")\n",
        "print(pd.DataFrame(results).T)\n",
        "\n",
        "# Step 7: Hyperparameter Tuning - RandomizedSearchCV for Random Forest\n",
        "param_dist_rf = {\n",
        "    'n_estimators': randint(50, 150),\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist_rf,\n",
        "                                      n_iter=10, cv=3, scoring='f1', random_state=42, verbose=2)\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "best_rf = random_search_rf.best_estimator_\n",
        "\n",
        "# Step 8: Hyperparameter Tuning - RandomizedSearchCV for SVM\n",
        "param_dist_svm = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "random_search_svm = RandomizedSearchCV(SVC(), param_distributions=param_dist_svm,\n",
        "                                       n_iter=5, cv=3, scoring='f1', random_state=42, verbose=2)\n",
        "random_search_svm.fit(X_train_scaled, y_train)\n",
        "best_svm = random_search_svm.best_estimator_\n",
        "\n",
        "# Step 9: Evaluate Tuned Models\n",
        "tuned_models = {\n",
        "    'Tuned Random Forest': best_rf,\n",
        "    'Tuned SVM': best_svm\n",
        "}\n",
        "\n",
        "for name, model in tuned_models.items():\n",
        "    if name == 'Tuned SVM':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        scores = evaluate_model(model, X_test_scaled, y_test)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        scores = evaluate_model(model, X_test, y_test)\n",
        "    results[name] = scores\n",
        "\n",
        "print(\"\\nAfter Hyperparameter Tuning Results:\")\n",
        "print(pd.DataFrame(results).T)\n",
        "\n",
        "# Step 10: Detailed Classification Report for Best Model (Tuned Random Forest)\n",
        "print(\"\\nClassification Report for Best Model (Tuned Random Forest):\")\n",
        "y_pred_best = best_rf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZjDDLA4ej0K",
        "outputId": "f207803b-a087-4d50-9df3-ae84ad70f632"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Model Evaluation Results:\n",
            "                     Accuracy  Precision    Recall  F1-Score\n",
            "Logistic Regression  0.973684   0.972222  0.985915  0.979021\n",
            "Random Forest        0.964912   0.958904  0.985915  0.972222\n",
            "SVM                  0.982456   0.972603  1.000000  0.986111\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=64; total time=   0.9s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=64; total time=   0.6s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=64; total time=   0.6s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=70; total time=   0.4s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=70; total time=   0.3s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=70; total time=   0.5s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=132; total time=   0.7s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=132; total time=   0.5s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=132; total time=   0.5s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=124; total time=   0.6s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=124; total time=   0.7s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=124; total time=   0.8s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=71; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=71; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=71; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=137; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=137; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=137; total time=   0.8s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=51; total time=   0.5s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=51; total time=   0.8s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=51; total time=   0.6s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=125; total time=   1.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=125; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=125; total time=   0.7s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=138; total time=   0.9s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=138; total time=   1.0s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=138; total time=   0.5s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=108; total time=   0.5s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=108; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=108; total time=   0.3s\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
            "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
            "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
            "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
            "[CV] END ...................C=100, gamma=auto, kernel=linear; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=scale, kernel=rbf; total time=   0.0s\n",
            "\n",
            "After Hyperparameter Tuning Results:\n",
            "                     Accuracy  Precision    Recall  F1-Score\n",
            "Logistic Regression  0.973684   0.972222  0.985915  0.979021\n",
            "Random Forest        0.964912   0.958904  0.985915  0.972222\n",
            "SVM                  0.982456   0.972603  1.000000  0.986111\n",
            "Tuned Random Forest  0.964912   0.958904  0.985915  0.972222\n",
            "Tuned SVM            0.982456   0.972603  1.000000  0.986111\n",
            "\n",
            "Classification Report for Best Model (Tuned Random Forest):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    }
  ]
}